# Set the default model config to clip,
# which adds special preprocessers to dataset_config.
includes:
- models/clip.yaml

dataset_config:
  news_clippings:
    # By default data_dir is ~/.cache/torch/mmf/data
    # An absolute path can be defined with a backslash
    data_dir: ${env.data_dir}/datasets
    option: ${env:split}
    annotations:
      train:
      - news_clippings/data/${env:split}/train.json
      val:
      - news_clippings/data/${env:split}/val.json
      test:
      - news_clippings/data/${env:split}/test.json
    images:
      train:
      - visual_news/origin
      val:
      - visual_news/origin
      test:
      - visual_news/origin

optimizer:
  type: adam_w
  params:
    lr: 5e-5
    eps: 1e-8
  allow_unused_parameters: True

# Typically one Nvidia GPU with 12212MiB
# can handle a batch size of 16
training:
  batch_size: 16

evaluation:
  metrics:
  - accuracy

scheduler:
  type: warmup_linear
  params:
    num_warmup_steps: 4000
    num_training_steps: 44000